FIR filter correction software 
------------------------------

Release 1.1 (98 NOV 16)

Frank Scherbaum 
Institut fuer Geowissenschaften
Universitaet Potsdam
POB 601553
14415 Potsdam

email: fs@geo.uni-potsdam.de


The theory for the correction method used is described in detail
in chapter 8 of my book: Of poles and zeros. Fundamentals of Digital Seismology.
Kluwer Academic Publisher, 256 pp., 1996. In short, it is based on
the replacement of the maximum phase portion of the linear-phase
FIR filter by its minimum phase equivalent. This is done by a
recursive allpass filter that works in reverse time. The coefficients
of the correction filter have all been calculated by polynomial rooting
(as described in my book) using Mathematica code. They are provided 
for a number of common data loggers in the subdirectory:  
./corr_coeffs below the present directory. The coefficients are kept
in what is called the protocol file (extension .prt) generated by 
my Mathematica program analysing a perticular FIR filter response.
E. g. the ones for the 320 Hz data stream of the Quanterra are kept in 
the file quant320Hz.prt.
 
In subdirectory ./src I am providing source code for the correction
of actual data together with a Makefile. Once these have been compiled,
e. g. by the calling sequence (from within subdirectory ./src):

make fir2caus
make interpolate
make decimate

Put the executables (fir2caus, interpol, decimate) into the subdirectory 
./bin and set the path to this directory, e.g. by:

set path = ($path ./distrib/bin)

You also need to set a environment variable  FIR_CORR_COEFF_PATH to the 
directory which contains the correction coefficients e.g. by:

setenv FIR_CORR_COEFF_PATH ./corr_coeffs/

The final slash is important. Of course it is more elegant to put the
appropriate commands into your .cshrc file.

Now you should be able to perform the correction for a particular data files
which have to be in a simple ASCII format (one data value per line) by  
executing  the appropriate shell script in the ./bin subdirectory. 

Before you do that, however, make sure that all the shell scripts
in the ./bin directory can be executed, e. g. by the command 
(from within the ./bin directory):

chmod a+x corr_*

The names of the shell scripts indicate the type of the datalogger whose correction coefficients
are used. E.g. corr_quanterra refers to the correction for the Quanterra data logger. 

!!! However, it is essential that you check these scripts carefully to see if they
are fully appropriate for your purpose.  These scripts serve the purpose to demonstrate
how the correction can be done. Depending on how many stage you want to correct,
you may have to adapt the script  for your purposes.  

There are two examples in the subdirectory ./example which help illustrate the
correction procedure: sgn.bhz (20 Hz Quanterra data stream) and sgn.hhz 
(80 Hz Quanterra data stream of the same event). Change into the subdirectory
./example and call 

corr_quanterra sgn.bhz 20

The correction script expects two command line arguments. The first one is
the file name, the second one is the sampling frequency for this file. If everything is installed correctly, first the shell script calls the interpolation program (interpol) to interpolate the 20 Hz data into 40 Hz. Subsequently, the FIR filter in this datastream is corrected for by using
the program fir2caus with the correction coefficients quant40Hz.prt. In the 
following steps, this procedure is repeated for the 80Hz and the 320Hz sampling rates. Finally, the corrected data are decimated back to 20Hz. The output file
gets the extension .corr. For the calling sequences for the individual
programs interpol, fir2caus, and decimate, you can either call them without
arguments or check the code. Please feel free to use the code for the implementation of the FIR filter correction in your own analysis system, but with the understanding that this code has been tested but still may contain bugs.

I would also be interested to learn if you do so because the code may be helpful for others including myself.
 
A final word about time shifts. Each correction stage changes the linear phase response
of a filter stage into an equivalent minimum phase filter stage and involves time shifts
of the onset. In other words, the onset times of your corrected record are to early by a 
certain amount. This time shift is printed during the correction for each stage. On my
machine the correction of the file sgn.bhz produces the following output:

Correction coefficient file: /home/frank/firfilt/corr_coeffs/quant40Hz.prt
Signal front advance in output trace: 31.500000 [samples] at 40.000000 [Hz] += 0.787500 [sec]
Correction coefficient file: /home/frank/firfilt/corr_coeffs/quant80Hz.prt
Signal front advance in output trace: 31.500000 [samples] at 80.000000 [Hz] += 0.393750 [sec]
Correction coefficient file: /home/frank/firfilt/corr_coeffs/quant320Hz.prt
Signal front advance in output trace: 35.500000 [samples] at 320.000000 [Hz] += 0.110937 [sec]
 
The total change of the time stamp of your record after the correction is the sum of
the individual signal front advances, here:

0.7875 + 0.39375 + 0.110937 seconds. 

Hence, the total signal front advance has to be added to an onset time picked on the 
FIR-filter-corrected trace. Don't be suprised if these times are considerably later than
onset times picked on the original trace still containing the linear phase FIR filter. Those will always be too early by an amount between zero and half the effective FIR filter length, while due to the apparent onset time delay on a causal filter (discussed in detail in Of poles and zeros), the onset on the FIR-filter-corrected trace will always be too late. Finally, the envelope of the corrected trace onset will also be delayed according to the group delay of the effective filter.  


