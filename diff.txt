diff --git a/CHANGELOG.md b/CHANGELOG.md
index 2176a1d..8be1ffc 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -97,11 +97,10 @@ method call parameters.  Created a readthedocs page.
 
 ## 0.5
 
-Added channel identification by ``tiskitpy_id``, which includes cleaning
-information.
-The ``tiskitpy_id`` for uncleaned data is the ``seed_id``.
-
-Added class CleanedStream and revised the guts of several classes, including
-renaming ``SpectralDensity.channel_names`` to ``SpectralDensity.ids``.
-
-_
\ No newline at end of file
+- Added channel identification by ``tiskitpy_id``, which includes cleaning
+  information.
+  The ``tiskitpy_id`` for uncleaned data is the ``seed_id``.
+- Added class CleanedStream and revised the guts of several classes, including
+  renaming ``SpectralDensity.channel_names`` to ``SpectralDensity.ids``.
+- CleanRotator class now has a property `variance_reduction` which gives the
+  variance reduction obtained during __init__()
\ No newline at end of file
diff --git a/docs/source/classes/decimator.rst b/docs/source/classes/decimator.rst
index 339d6e2..2891287 100644
--- a/docs/source/classes/decimator.rst
+++ b/docs/source/classes/decimator.rst
@@ -32,6 +32,13 @@ Methods
 - ``update_inventory_from_nslc(inv ...)``: Return inventory with only the
   specified network, station, channel, location(s) updated
  
+ Command-line programs
+---------------------
+
+Use these programs' `-h` option for help
+
+- ``tiskitpy_decimate_SDS``: Decimates the data in an SDS directory and updates
+    the corresponding inventory file.
 
 Example
 ---------------------
diff --git a/docs/source/classes/spectral_density.rst b/docs/source/classes/spectral_density.rst
index a39de5a..8a259c0 100644
--- a/docs/source/classes/spectral_density.rst
+++ b/docs/source/classes/spectral_density.rst
@@ -64,6 +64,7 @@ Other Methods
   for the given channels
 - ``plot_one_coherence(in_id, out_id, ...)``: plot coherence
   for the given channels
+- ``plots(spectra_list, ...)``: overlay plot spectra specified in the list
 
 Set Methods
 ^^^^^^^^^^^^^^^^^^
diff --git a/docs/source/conf.py b/docs/source/conf.py
index 3a7ae9d..a2d12bc 100644
--- a/docs/source/conf.py
+++ b/docs/source/conf.py
@@ -23,7 +23,7 @@ copyright = '2022, IPGP'
 author = 'Wayne Crawford' 
 
 # The full version, including alpha/beta/rc tags
-release = '0.4'
+release = '0.5rc1'
 
 
 # -- General configuration ---------------------------------------------------
diff --git a/setup.py b/setup.py
index e3f6b80..98996e0 100644
--- a/setup.py
+++ b/setup.py
@@ -22,7 +22,8 @@ setuptools.setup(
                       'xarray'],
     entry_points={
          'console_scripts': [
-            'tiskitpy_decimate_SDS=tiskitpy.decimate.decimate_SDS:main'
+            'tiskitpy_decimate_SDS=tiskitpy.scripts.decimate_SDS:main', 
+            'tiskitpy_get_SDS_inventory=tiskitpy.scripts.get_SDS_inventory:main'
          ]
     },
     python_requires='>=3.8',
diff --git a/tests/test_clean_rotator.py b/tests/test_clean_rotator.py
index 18ab2d7..9dbe2b1 100755
--- a/tests/test_clean_rotator.py
+++ b/tests/test_clean_rotator.py
@@ -33,8 +33,8 @@ class TestMethods(unittest.TestCase):
             remove_eq=str(self.test_path /
                           "20161205T-20161207T_MM5.85_eqcat.qml"),
             save_eq_file=False)
-        self.assertAlmostEqual(rotator.angle, -0.18, delta=0.01)
-        self.assertAlmostEqual(rotator.azimuth, 61.67, delta=0.01)
+        self.assertAlmostEqual(rotator.angle, 0.18, delta=0.01)
+        self.assertAlmostEqual(rotator.azimuth, 241.67, delta=0.01)
         
         rot_stream = rotator.apply(stream)
         rotZ = rot_stream.select(channel='*Z')[0]
diff --git a/tests/test_decimate.py b/tests/test_decimate.py
index 58575d6..e0bc27f 100755
--- a/tests/test_decimate.py
+++ b/tests/test_decimate.py
@@ -67,9 +67,9 @@ class TestMethods(unittest.TestCase):
             stage_sequence_number=0,
             stage_gain=1,
             stage_gain_frequency=0,
-            input_units='counts',
+            input_units='count',
             input_units_description='digital counts',
-            output_units='counts',
+            output_units='count',
             output_units_description='digital counts',
             symmetry='NONE',
             name=name,
diff --git a/tiskitpy/__init__.py b/tiskitpy/__init__.py
index e73d895..e170361 100644
--- a/tiskitpy/__init__.py
+++ b/tiskitpy/__init__.py
@@ -33,10 +33,12 @@ Functions
 Command-line programs
 =========================
 
+Use the `-h` option for help
+
 - ``tiskitpy_decimate_SDS`` : Decimate data stored in a SeisComp Data Structure
-    database.
-    Inserts the data into the same database and creates a new StationXML file
-    (based on an existing StationXML file for the input database)
+  database.
+- ``tiskitpy_get_SDS_inventory``: Return the inventory corresponding to a
+  SeisComp Data Structure database, using the FDSN Station webservice
 """
 from .clean_rotator import CleanRotator
 from .cleaned_stream import CleanedStream
diff --git a/tiskitpy/clean_rotator.py b/tiskitpy/clean_rotator.py
index 39b9cb4..13b52c2 100644
--- a/tiskitpy/clean_rotator.py
+++ b/tiskitpy/clean_rotator.py
@@ -41,6 +41,8 @@ class CleanRotator:
     Attributes:
         angle (float): angle by which Z (or Z-X-Y) was rotated
         azimuth (float): azimuth by which Z (or Z-X-Y) was rotated
+        variance_reduction (float): amount by which variance was reduced during
+            calculation (0 to 1)
     """
 
     def __init__(self, stream, avoid_spans=None, plot=False, quickTest=False,
@@ -48,7 +50,6 @@ class CleanRotator:
                  filt_band=(0.001, 0.01), save_eq_file=True):
         """
         Calculate rotation angles needed to minimize noise on vertical channel
-
         """
         ignore_spans = self._make_eq_spans(
             remove_eq, stream[0].stats, verbose, save_eq_file
@@ -57,20 +58,20 @@ class CleanRotator:
             ignore_spans += avoid_spans
         filtstream = self._filtstream(stream, filt_band)
         srData = SeisRotate(filtstream)
-        (ang, azi) = srData.calc_zrotate_opt(
-            verbose=verbose, ignore_spans=ignore_spans, uselogvar=uselogvar
+        (ang, azi, var_red) = srData.calc_zrotate_opt(
+            ignore_spans=ignore_spans, uselogvar=uselogvar
         )
-        if verbose:
-            logger.info(f"    Best angle= azimuth is ({ang:.2f}, {azi:.2f})")
         self.angle = ang
         self.azimuth = azi
+        self.variance_reduction = var_red
+        if verbose:
+            logger.info(self.__str__())
         if plot:
             self._plot_filtered_stream(stream, filt_band)
 
     def __str__(self):
-        return "CleanRotator: angle, azimuth = {:.2f}, {:.1f} degrees".format(
-            self.angle, self.azimuth
-        )
+        return "CleanRotator: angle, azimuth, var_red = {:5.2f}, {:6.1f}, {:3.2f}".format(
+            self.angle, self.azimuth, self.variance_reduction)
 
     def _filtstream(self, stream, filt_band):
         """Filter data to tilt noise band for best Angle calc"""
@@ -114,7 +115,7 @@ class CleanRotator:
         compare_stream = Stream([trace_view_Z, trace_view_rot_Z])
         compare_stream.plot(equal_scale=True, method="full")
 
-    def apply(self, stream, horiz_too=False):
+    def apply(self, stream, horiz_too=False, rot_limit=20.):
         """
         Rotates vertical channel to minimize noise
 
@@ -124,10 +125,14 @@ class CleanRotator:
             horiz_too: (bool) rotate horizontals also (use if you believe
                 channels are truly orthogonal, probably a bad idea anyway
                 as long as we use a 2-value rotation)
+            rot_limit (float): Do not rotate if self.angle greater then this value
         Returns:
             strm_rot (Stream): rotated stream
         """
         seis_stream, other_stream = SeisRotate.separate_streams(stream)
+        if self.angle > rot_limit:
+            logger.warning(f'{self.angle=} > {rot_limit=}, not rotating!')
+            return stream
         srData = SeisRotate(stream)
         srData.zrotate(self.angle, self.azimuth, horiz_too)
         srData.Z = CS.tag(srData.Z, TRANS_CODE)
@@ -173,17 +178,3 @@ def rotate_clean(stream, avoid_spans=None, horiz_too=False, plot=False,
                        uselogvar, verbose, filt_band)
     return obj.apply(stream), obj.rot_angle, obj.rot_azimuth
 
-
-# def extract_corr_z(evstream, tf_name):
-#     """
-#     Return a corrected stream from ATACR EventStream
-#
-#     Args:
-#         evstream (:class:`obstools.atacr.EventStream`):
-#         tf_name (str): transfer function key
-#     Returns:
-#         outstream (Stream): corrected Z stream
-#     """
-#     stream = evstream.sth.select(component='Z').copy()
-#     stream[0].data = evstream.correct[tf_name].flatten()
-#     return stream
diff --git a/tiskitpy/data_cleaner/data_cleaner_tf.py b/tiskitpy/data_cleaner/data_cleaner_tf.py
index 14f42d3..fef0312 100644
--- a/tiskitpy/data_cleaner/data_cleaner_tf.py
+++ b/tiskitpy/data_cleaner/data_cleaner_tf.py
@@ -16,7 +16,7 @@ from ..response_functions import ResponseFunctions
 from ..spectral_density import SpectralDensity
 from .rf_list import RFList
 from ..cleaned_stream import CleanedStream
-from ..utils import CleanSequence as CS
+from ..utils import CleanSequence as CS, stream_synchronize
 from tiskitpy.logger import init_logger
 
 logger = init_logger()
@@ -188,11 +188,9 @@ class DataCleaner:
                 out_trace = out_stream.select(id=out_id)[0]
                 out_stream.remove(out_trace)
                 out_trace = self._correct_trace(
-                    in_trace,
-                    out_trace,
-                    rfs.freqs,
-                    rfs.corrector_wrt_counts(out_id),
-                    in_time_domain,
+                    in_trace, out_trace,
+                    rfs.freqs, rfs.corrector_wrt_counts(out_id),
+                    in_time_domain
                 )
                 out_trace = CS.tag(out_trace, in_trace.id)
                 out_stream += out_trace
@@ -204,7 +202,8 @@ class DataCleaner:
         """
         self.RFList.plot()
 
-    def _correct_trace(self, in_trace, out_trace, f, rf, in_time_domain=False):
+    def _correct_trace(self, in_trace, out_trace, f, rf, in_time_domain=False,
+                       max_reject_sync=0.01):
         """
         Correct a trace using an input trace and a frequency response function
 
@@ -217,14 +216,17 @@ class DataCleaner:
             rf (:class:`numpy.ndarray`): frequency response function between the input
                 and output traces (counts/count)
             in_time_domain (bool): do correction in time domain
+            max_reject_sync (float): max_reject for stream_synchronize()
 
         Returns:
             out_trace_corrected (:class:`obspy.core.trace.Trace`): corrected
                 output trace
         """
-        self._validate_streams_synchronized(in_trace, out_trace)
-        in_trace = in_trace.copy()
-        out_trace = out_trace.copy()
+        stream = stream_synchronize(Stream([in_trace, out_trace]), max_reject_sync)
+        in_trace, out_trace = stream[0], stream[1]
+        # self._validate_streams_synchronized(in_trace, out_trace)
+        # in_trace = in_trace.copy()
+        # out_trace = out_trace.copy()
         in_trace.detrend("linear")
         out_trace.detrend("linear")
         if in_time_domain:
diff --git a/tiskitpy/decimate/decimate_SDS.py b/tiskitpy/decimate/decimate_SDS.py
deleted file mode 100644
index 00d8725..0000000
--- a/tiskitpy/decimate/decimate_SDS.py
+++ /dev/null
@@ -1,123 +0,0 @@
-"""
-Script to decimate SDS data, stuff new channels into the SDS structure
-and return the modified inventory
-"""
-import argparse
-from pathlib import Path
-
-from obspy.core.stream import read
-from obspy.core.inventory import read_inventory
-
-from .decimator import Decimator
-from ..logger import init_logger
-
-logger = init_logger()
-
-
-def decimate_SDS(SDS_root, inv, input_sample_rate, decim_list):
-    """
-    The main function
-
-    Should ensure continuity across day and year boundaries.
-    Currently just checks if the requested decimation is an integral divisor
-    of the current day's samples and returns an error if not
-    Only works for broad-band channels
-
-    Args:
-        SDS_root (str or Path): SDS root directory
-        inv (:class:`obspy.core.inventory.Inventory`): station inventory
-        input_sample_rate (float): sample rate of data to process
-        decim_list (list): list of decimation factors (integers between
-            2 and 7)
-    """
-    SDS_root = Path(SDS_root)
-    decimator = Decimator(decim_list)
-    output_sample_rate = input_sample_rate/decimator.decimation_factor
-    in_band_code = Decimator.get_band_code('B', input_sample_rate)
-    out_band_code = Decimator.get_band_code('B', output_sample_rate)
-    logger.info('output sampling rate will be {:g} sps, band code will be {}'
-                 .format(output_sample_rate, out_band_code))
-    if in_band_code == out_band_code:
-        raise ValueError(f'identical input & output band codes: {in_band_code}')
-
-    for year_dir in [x for x in SDS_root.iterdir() if x.is_dir()]:
-        logger.info(f' year={str(year_dir.name)}')
-        for net_dir in [x for x in year_dir.iterdir() if x.is_dir()]:
-            logger.info(f'\tnet={str(net_dir.name)}')
-            for sta_dir in [x for x in net_dir.iterdir() if x.is_dir()]:
-                logger.info(f'\t\tstation={str(sta_dir.name)}')
-                for cha_dir in [x for x in sta_dir.iterdir() if x.is_dir()]:
-                    logger.info(f'\t\t\tchannel={str(cha_dir.name)}')
-                    cha_name = cha_dir.name
-                    if not cha_name[0] == in_band_code:
-                        continue
-                    out_cha_dir = (sta_dir / (out_band_code + cha_name[1:]))
-                    out_cha_dir.mkdir()
-                    logger.info('\t\t\t\tCreating output channel dir "{}"'
-                                 .format(out_cha_dir.name))
-                    files = list(cha_dir.glob(f'*.{cha_name}.*'))
-                    logger.info(f'\t\t\t\t{len(files):d} files to process')
-                    for f in files:
-                        stream = read(str(f), 'MSEED')
-                        if stream[0].stats.npts % decimator.decimation_factor == 0:
-                            ValueError(
-                                f"day's stream length ({stream[0].stats.npts})"
-                                " is not divisible by decimator "
-                                f"({decimator.decimation_factor})")
-                        if stream[0].stats.sampling_rate != input_sample_rate:
-                            logger.warning(
-                                f"{str(f)} first block's sampling rate != "
-                                f"{input_sample_rate}, skipping...")
-                        net, sta, loc, ich, typ, yr, dy = str(f.name).split('.')
-                        d_stream = decimator.decimate(stream)
-                        och = out_band_code + ich[1:]
-                        outfname = f'{net}.{sta}.{loc}.{och}.{typ}.{yr}.{dy}'
-                        d_stream.write(out_cha_dir / outfname, 'MSEED')
-                    inv = decimator.update_inventory(inv, stream)
-    return inv
-
-
-def decimate_SDS_StationXML(SDS_root, inv_file, input_sample_rate, decim_list,
-                            output_file=None):
-    """
-    Applies decimate_SDS when the inventory is in a StationXML file
-
-    Args:
-        SDS_root (str or Path): SDS root directory
-        inv_file (str or Path): Path to StationXML file
-        input_sample_rate (float): sample rate of data to process
-        decim_list (list): list of decimation factors (integers between
-            2 and 7)
-        output_file (str): output StationXML filename (None => 
-            infile.replace('.xml', '_decim.xml'))
-
-    The output StationXML file will have the suffix  `_decim.xml`
-    """
-    inv = read_inventory(inv_file, 'STATIONXML')
-    inv = decimate_SDS(SDS_root, inv, input_sample_rate, decim_list)
-    if output_file is None:
-        output_file = inv_file.replace('.xml', '_decim.xml')
-    inv.write(output_file, format="STATIONXML")
-
-
-def main():
-    parser = argparse.ArgumentParser(
-        description="Insert decimated channels and create new StationXML file"
-    )
-    parser.add_argument("SDS_root", help='SDS root directory')
-    parser.add_argument("inv_file",
-                        help="StationXML file")
-    parser.add_argument("input_sample_rate", type=float,
-                        help="Process only channels having this sample rate")
-    parser.add_argument("decim_factor", type=int, nargs="+",
-                        choices=[2,3,4,5,6,7],
-                        help="Sequence of decimation factors to use")
-    parser.add_argument("--of", dest="output_file", default=None,
-                        help="Output StationXML filename "
-                             "(default = infile.replace('.xml', '_decim.xml')")
-    parser.add_argument("-q", "--quiet", action="store_true",
-                        help="Suppress information messages")
-    args = parser.parse_args()
-    decimate_SDS_StationXML(args.SDS_root, args.inv_file,
-                            args.input_sample_rate, args.decim_factor,
-                            args.output_file)
diff --git a/tiskitpy/decimate/decimator.py b/tiskitpy/decimate/decimator.py
index 62ce37b..73dd5ef 100755
--- a/tiskitpy/decimate/decimator.py
+++ b/tiskitpy/decimate/decimator.py
@@ -16,11 +16,13 @@
 # import obspy
 # from obspy.clients.filesystem import sds
 import time
+# from copy import deepcopy
 from dataclasses import dataclass
 from inspect import getfile, currentframe
 from pathlib import Path
 import warnings
 import fnmatch
+# import logging
 
 from numpy import prod
 from obspy.core.stream import Stream, Trace
@@ -49,6 +51,12 @@ class Decimator:
     decimates: list
     verbose: bool = False
 
+    # def __post_init__(self):
+    #     if self.verbose is True:
+    #         logger.setLevel(logging.INFO)
+    #     else:
+    #         logger.setLevel(logging.WARN)
+
     @property
     def decimation_factor(self):
         """Total decimation (product of `decimates`)"""
@@ -247,16 +255,16 @@ class Decimator:
             normalize_firs (bool): normalizes any FIR channel that isn't
                 already
         """
-        logger.info("channel modified from {} ({} sps)".format(
-              ".".join([net, sta, cha.location_code, cha.code]),
-              cha.sample_rate))
+        old_seed_id = ".".join([net, sta, cha.location_code, cha.code])
+        # old_cha = cha.copy()
         input_sample_rate = cha.sample_rate
         self._add_instrument_response(cha, input_sample_rate)
         self._change_chan_loc(cha, input_sample_rate)
         cha.sample_rate /= self.decimation_factor
-        logger.info("to {} ({:g} sps)".format(
-                    ".".join([net, sta, cha.location_code, cha.code]),
-                    cha.sample_rate))
+        seed_id = ".".join([net, sta, cha.location_code, cha.code])
+        logger.info("channel modified from "
+                    f"{old_seed_id} ({input_sample_rate:g} sps) "
+                    f"to {seed_id} ({cha.sample_rate:g} sps) ")
 
     @staticmethod
     def _normalize_firs(cha):
@@ -282,7 +290,7 @@ class Decimator:
                     )
                 if abs(coeff_sum - 1) > 0.01:
                     logger.info(f"DECIMATOR: Sum of FIR coeffs = "
-                                 f"{coeff_sum}, normalizing")
+                                f"{coeff_sum}, normalizing")
                     stg.coefficients = [x / coeff_sum
                                         for x in stg.coefficients]
             elif isinstance(stg, CoefficientsTypeResponseStage):
@@ -354,14 +362,17 @@ class Decimator:
 
     def _add_instrument_response(self, cha, input_sample_rate):
         """
-        Append  decimation object's instrument response to an existing channel's response
+        Append  decimation object's instrument response to an existing
+        channel's response
         """
         stage_number = cha.response.response_stages[-1].stage_sequence_number
         for d in self.decimates:
             fir_filter = FIRFilter.from_SAC(d)
             stage_number += 1
             cha.response.response_stages.append(
-                fir_filter.to_obspy(input_sample_rate, stage_number)
+                fir_filter.to_obspy(
+                    input_sample_rate, stage_number,
+                    cha.response.response_stages[-1].output_units)
             )
             input_sample_rate /= d
         try:
@@ -385,7 +396,7 @@ class Decimator:
             newtr.append(self._run_trace(tr))
         st.traces = newtr
         logger.info("New data has {} samples".format([tr.data.size
-                                                for tr in st]))
+                                                      for tr in st]))
         st.verify()
         return st
 
diff --git a/tiskitpy/decimate/fir_filter.py b/tiskitpy/decimate/fir_filter.py
index 47aaa35..7e6dffa 100755
--- a/tiskitpy/decimate/fir_filter.py
+++ b/tiskitpy/decimate/fir_filter.py
@@ -107,17 +107,22 @@ class FIRFilter:
             raise NameError(f"FIR symmetry = {symmetry_code} not implemented")
         return
 
-    def to_obspy(self, sampling_rate, stage_sequence_number=0):
+    def to_obspy(self, sampling_rate, stage_sequence_number=0,
+                 prior_output_units=False):
         """
         Return an obspy FIRResponseStage
         """
+        units = 'count'     # StationXML recommendation
+        if prior_output_units is not False:
+            if prior_output_units[:5].lower() == 'count':
+                units = prior_output_units
         return FIRResponseStage(
             stage_sequence_number=stage_sequence_number,
             stage_gain=1,
             stage_gain_frequency=0,
-            input_units="counts",
+            input_units=units,
             input_units_description="digital counts",
-            output_units="counts",
+            output_units=units,
             output_units_description="digital counts",
             symmetry="NONE",
             name=self.name,
diff --git a/tiskitpy/logger.py b/tiskitpy/logger.py
index 0a1d2f5..b8baf08 100755
--- a/tiskitpy/logger.py
+++ b/tiskitpy/logger.py
@@ -78,8 +78,7 @@ def init_logger(file_level='DEBUG', console_level='INFO',
         fmt='{asctime} {levelname:<8s} {module}.{funcName}(): {message}',
         style='{', datefmt='%Y-%m-%d %H:%M:%S'))
     fileHandler.setLevel(file_level.upper())
-    
-    
+
     # Console Handler
     console_log_output = console_log_output.lower()
     if (console_log_output == "stdout"):
@@ -100,3 +99,40 @@ def init_logger(file_level='DEBUG', console_level='INFO',
     logger.addHandler(consoleHandler)
 
     return logger
+    
+def change_level(logger, htype, level):
+    """
+    Change a handler's logging level
+    
+    Args:
+        htype (str): handler type: 'console' or 'file'
+        level (str): 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'
+    """
+    assert htype.upper() in ['CONSOLE', 'FILE']
+    assert level.upper() in ['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL']
+
+    if htype.upper() == 'CONSOLE':
+        handler_type = logging.StreamHandler
+    else:
+        handler_type = logging.RotatingFileHandler
+    for handler in logger.handlers:
+        if isinstance(handler, handler_type):
+            handler.setLevel(level)
+
+def change_console_level(logger, level):
+    """
+    Change consoleHandlers logging level
+    
+    Args:
+        level (str): 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'
+    """
+    change_level(logger, 'console', level)
+
+def change_file_level(logger, level):
+    """
+    Change fileHandler's logging level
+    
+    Args:
+        level (str): 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'
+    """
+    change_level(logger, 'file', level)
diff --git a/tiskitpy/spectral_density/spectral_density.py b/tiskitpy/spectral_density/spectral_density.py
index 6dcfc62..cfc0f96 100644
--- a/tiskitpy/spectral_density/spectral_density.py
+++ b/tiskitpy/spectral_density/spectral_density.py
@@ -720,6 +720,7 @@ class SpectralDensity:
 
     @staticmethod
     def plots(sds,
+              line_kws=None,
               x=None,
               overlay=True,
               plot_peterson=True,
@@ -732,9 +733,14 @@ class SpectralDensity:
 
         Args:
             sds (list): SpectralDensity functions to plot
+            line_kws(list of dict): Line keywords for each SpectralDensity function
         Other Properties:
             **kwargs: any arguments used in plot_autospectra, except
                 overlay (always true)
+        Returns:
+            figinfo (list):
+                fig
+                axa (): amplitude axis
         """
         # Validate inputs
         if overlay is not True:
@@ -744,16 +750,21 @@ class SpectralDensity:
         for sd in sds:
             if not isinstance(sd, SpectralDensity):
                 raise ValueError('sds element is not a SpectralDensity object')
+        if line_kws is not None:
+            if not len(line_kws) == len(sds):
+                raise ValueError(f'{len(line_kws)=} != {len(sds)=}')
+        else:
+            line_kws = [{} for x in sds]
 
         rows, cols = 1, 1
-        ax_array = np.ndarray((rows, cols), dtype=tuple)
         fig, axs = plt.subplots(rows, cols, sharex=True, **fig_kw)
         if title is None:
             title = "Auto-spectra, multiple SpectralDensities"
         fig.suptitle(title)
         axa, axp = None, None
         first_time = True
-        for sd in sds:
+        for sd, l_kw in zip(sds, line_kws):
+            assert isinstance(l_kw, dict)
             new_x = sd._get_validate_ids(x)
             for key, i in zip(new_x, range(len(new_x))):
                 axa, axp = sd.plot_one_spectra(
@@ -768,16 +779,17 @@ class SpectralDensity:
                     ax_p=axp,
                     show_phase=False,
                     plot_peterson=plot_peterson,
-                    annotate=False
+                    annotate=False,
+                    **fig_kw,
+                    **l_kw
                 )
                 first_time = False
-        ax_array[0, 0] = (axa, axp)
         plt.legend(fontsize='small')
         if outfile:
             plt.savefig(outfile)
         if show:
             plt.show()
-        return ax_array
+        return fig, axa
 
     def plot(self, **kwargs):
         """Shortcut for `plot_autospectra()`"""
@@ -940,7 +952,8 @@ class SpectralDensity:
         show_phase=True,
         plot_peterson=True,
         outfile=None,
-        annotate=True
+        annotate=True,
+        **plot_kws
     ):
         """
         Plot one spectral density
@@ -968,6 +981,7 @@ class SpectralDensity:
             plot_peterson(bool): plot Peterson Noise model if channel has
                 units of :math:`(m/s^2)^2/Hz`
             outfile (str): save figure to this filename
+            **plot_kws (dict): keywords to pass on to plot command
 
         Returns:
             (tuple): tuple containing
@@ -1024,7 +1038,7 @@ class SpectralDensity:
             label = f"{subkey} ({PSD_units})"
         elif label == "units":
             label = f"{PSD_units}"
-        ax_a.semilogx(f, 10 * np.log10(np.abs(psd)), label=label)
+        ax_a.semilogx(f, 10 * np.log10(np.abs(psd)), label=label, **plot_kws)
         ax_a.set_xlim(f[1], f[-1])
         if plot_peterson is True and PSD_units.lower() == "(m/s^2)^2":
             lownoise, highnoise = Peterson_noise_model(f, True)
@@ -1050,7 +1064,7 @@ class SpectralDensity:
                     (3 * fig_grid[0], 1 * fig_grid[1]),
                     (3 * plot_spot[0] + 2, plot_spot[1] + 0),
                 )
-            ax_p.semilogx(f, np.degrees(np.angle(psd)))
+            ax_p.semilogx(f, np.degrees(np.angle(psd), **plot_kws))
             ax_p.set_ylim(-180, 180)
             ax_p.set_xlim(f[1], f[-1])
             ax_p.set_yticks((-180, 0, 180))
diff --git a/tiskitpy/time_spans.py b/tiskitpy/time_spans.py
index 623705d..ce85b5a 100755
--- a/tiskitpy/time_spans.py
+++ b/tiskitpy/time_spans.py
@@ -113,18 +113,24 @@ class TimeSpans:
         if Path(eq_file).is_file():
             cat = read_events(eq_file, format="quakeml")
         else:
-            logger.info("Reading EQs from USGS online catalog...")
-            cat = Client("USGS").get_events(
-                starttime=starttime
-                - _calc_eq_cut(9, minmag, days_per_magnitude),
-                endtime=endtime,
-                minmagnitude=minmag,
-                orderby="time-asc",
-            )
-            logger.info("Done")
-            logger.info(f'writing catalog to "{eq_file}"')
-            if save_eq_file:
-                cat.write(eq_file, format="quakeml")
+            logger.info(f"Didn't find local EQ file '{eq_file}', reading from USGS online catalog...")
+            try:
+                cat = Client("USGS").get_events(
+                    starttime=starttime
+                    - _calc_eq_cut(9, minmag, days_per_magnitude),
+                    endtime=endtime,
+                    minmagnitude=minmag,
+                    orderby="time-asc",
+                )
+                logger.info("Done")
+                logger.info(f'writing catalog to "{eq_file}"')
+                if save_eq_file:
+                    cat.write(eq_file, format="quakeml")
+            except Exception as e:  # except FDSNNoServiceException as e:
+                logger.warning(e)
+                logger.warning('!!!Continuing without removing EQs!!!')
+                return cls([])
+            
 
         new_cat = Catalog(
             events=[x for x in cat if x.preferred_magnitude().mag >= minmag]
diff --git a/tiskitpy/utils/__init__.py b/tiskitpy/utils/__init__.py
index 0d6a4d3..be8375e 100644
--- a/tiskitpy/utils/__init__.py
+++ b/tiskitpy/utils/__init__.py
@@ -2,7 +2,6 @@
 Utility routines
 """
 from .seis_rotate import SeisRotate
-# from .cleaner_string import CleanerString  # Should disappear (part of CleanSequence)
 from .clean_sequence import CleanSequence
-# from .remove_cleaner_string import remove_cleaner_string
 from .functions import get_full_id, match_one_str
+from .stream_synchronize import stream_synchronize
diff --git a/tiskitpy/utils/seis_rotate.py b/tiskitpy/utils/seis_rotate.py
index 64ac091..88dc098 100644
--- a/tiskitpy/utils/seis_rotate.py
+++ b/tiskitpy/utils/seis_rotate.py
@@ -14,6 +14,7 @@ from obspy.signal.rotate import rotate2zne
 from obspy.core.stream import Stream  # , Trace
 
 from ..logger import init_logger
+from .stream_synchronize import stream_synchronize
 
 logger = init_logger()
 
@@ -24,7 +25,7 @@ class SeisRotate:
     non-deforming rotation
     """
 
-    def __init__(self, stream, uselogvar=False):
+    def __init__(self, stream, uselogvar=False, max_reject_sync=0.01):
         """
         Create a seisRotate object from a 3-component obsPy Stream
 
@@ -32,6 +33,7 @@ class SeisRotate:
             stream (Stream): 3+ component data stream
             uselogvar(bool): use logarithmic variance when searching for
                              best angles
+            max_reject_sync(): max_reject value for stream_synchronize()
 
         Channel names must end in Z, N and E or Z, 1, and 2
         Z is up, 1 and 2 are horizontal orthogonal with 2 90Â° clockwise
@@ -39,6 +41,7 @@ class SeisRotate:
         except that they are not necessarily aligned with geographic
         cardinals)
         """
+        stream = stream_synchronize(stream, max_reject_sync)
         self.uselogvar = uselogvar
         self.Z, self.N, self.E = SeisRotate._get_seis_traces(stream)
         self.fs = self.Z.stats.sampling_rate
@@ -118,19 +121,22 @@ class SeisRotate:
         lowcut=0.001,
         hicut=0.005,
         ignore_spans=None,
-        uselogvar=None,
-        verbose=False,
+        uselogvar=None
     ):
         """
         Calculate the Z channel rotation angle that minimizes tilt noise
 
         Arguments:
-            lowcut (float): low passband frequency in which to lood for energy
-                             reduction
+            lowcut (float): low passband frequency in which to evaluate
+                            variance reduction
             hicut (float): high passpand frequency "" "" ""
             ignore_spans (:class:`TimeSpans``): time spans to ignore
             uselogvar(bool): use logarithmic variance estimate
-            verbose (bool): output information about the angles tested?
+
+        Returns: (tuple)
+            angle (float): tilt angle (degrees, 0 means no tilt correction)
+            azimuth (float): tilt azimuth (degrees)
+            var_red (float): obtained reduction in variance (0 to 1)
 
         The default (lowcut, hicut) values of (0.001, 0.005) correspond to the
         band where removing tilt noise generally has the greatest effect on
@@ -152,14 +158,13 @@ class SeisRotate:
             filt.E = ignore_spans.zero(filt.E)
 
         # Quick estimate of angles using Z/E and Z/N ratios. DOESN'T HELP: SKIP
-        # (startAngle,startAzimuth)=filt._estimateAngles(verbose)
         startAngle, startAzi = (0, 0)
 
         # Search for the best angles
-        angle, azimuth = filt._searchBestAngles(startAngle, startAzi, verbose)
-        return angle, azimuth
+        angle, azimuth, var_red = filt._searchBestAngles(startAngle, startAzi)
+        return angle, azimuth, var_red
 
-    def _estimateAngles(self, verbose=False):
+    def _estimateAngles(self):
         """
         Estimate how far and in which direction Z is tilted from vertical
         by comparing with N and E
@@ -173,8 +178,6 @@ class SeisRotate:
         (transients, etc) for this to work.  Also doesn't account for any time
         lags: might work better if ratios calculated from cross-corellation
 
-        Arguments:
-            verbose (bool): display extra information?
         """
         logger.debug("Estimating preliminary angle based on signal ratios")
         ZoverN = np.divide(self.Z.data, self.N.data)
@@ -210,19 +213,19 @@ class SeisRotate:
 
         return angle, azimuth
 
-    def _searchBestAngles(self, startAngle=0, startAzimuth=0, verbose=False):
+    def _searchBestAngles(self, startAngle=0, startAzimuth=0):
         """
         Find best Z rotation angles
 
         Arguments:
             startAngle (float): starting guess for the angle (degrees)
             startAzimuth (float): starting guess for the azimuth (degrees)
-            verbose (bool): display extra information?
 
         Returns:
             (tuple): 2-tuple containing:
-                angle (float): best angle (degrees)
-                azimuth (float): best azimuth (degrees)
+                angle (float): best angle (degrees, 0 to 90)
+                azimuth (float): best azimuth (degrees, 0 to 360)
+                var_red (float): variance reduction (0 to 1)
 
         Searches for minimum Z energy as function of angle
         """
@@ -237,29 +240,28 @@ class SeisRotate:
             full_output=True,
             retall=True,
         )
-        bestAngles = xopt
+        bestAngle, bestAzimuth = xopt
+        if bestAngle < 0:
+            bestAngle = -bestAngle
+            bestAzimuth += 180
+        bestAzimuth %= 360.
+        if bestAngle > 90:
+            logger.warning(f'bestAngle > 90! ({bestAngle})')
+
+        logger.debug(f"{xopt=}, {fopt=}, {iter=}, {funcalls=}, {warnflag=}")
 
-        if verbose is True:
-            logger.info(f"{fopt=}, {iter=}, {funcalls=}")
-            logger.debug(f"{xopt=}, {warnflag=}")
-        else:
-            logger.debug(f"{xopt=}, {fopt=}, {iter=}, {funcalls=}, {warnflag=}")
-        
         if self.uselogvar is False:
-            logger.info(
-                "    variance reduced from "
-                "{:.2e} to {:.2e} ({:.1f}% lower)".format(
-                    start_var, fopt,
-                    100 * (1 - fopt / start_var)))
+            var_red = 1 - fopt / start_var
+            logger.debug("    variance reduced from {:.2e} to {:.2e} ({:.1f}% lower)"
+                        .format(start_var, fopt, 100 * var_red))
         else:
-            logger.info("    log variance reduced from "
-                  "{:.1f} to {:.1f} ({:.1f}% lower)".format(
-                      start_var, fopt,
-                      100 * (1 - 10 ** (fopt - start_var))))
+            var_red = 1 - 10 ** (fopt - start_var)
+            logger.debug("    log variance reduced from {:.1f} to {:.1f} ({:.1f}% lower)"
+                        .format(start_var, fopt, 100 * var_red))
         if warnflag:
-            logger.info(f"{allvecs=}")
+            logger.debug(f"optimization warning flag: {allvecs=}")
 
-        return (bestAngles[0], bestAngles[1])
+        return (bestAngle, bestAzimuth, var_red)
 
     def _rotZ_variance(self, angles):
         """
